from __future__ import print_function
import torch.nn as nn
import torch.optim as optim
import torch.utils.data
import torchvision.utils as vutils
from torch.autograd import Variable
from torchvision import transforms
from torchvision.datasets import ImageFolder
import os

from generator import Generator
from discriminator import Discriminator

# Setting some parameters
batchSize = 4
imageSize = 64
num_epochs = 10000

# Creating the transformations (scaling, tensor conversion, normalization) to apply to the input images.
transform = transforms.Compose([transforms.Resize((imageSize, imageSize)), transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

# Loading the dataset
dataset = ImageFolder('/dataset/', transform=transform)
data_loader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True,
                                          num_workers=2)


def weights_init(m):
    """
    Initialize weights of a neural network.

    Arguments:
        m: Neural network which needs to be initialized.
    """
    class_name = m.__class__.__name__
    if class_name.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif class_name.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)


# Creating the generator
netG = Generator()
netG.apply(weights_init)

# Creating the discriminator
netD = Discriminator()
netD.apply(weights_init)

os.makedirs("results", exist_ok=True)

# Training the DCGANs

# We create a criterion object that will measure the error between the prediction and the target.
# TODO: Use SGD for discriminator and ADAM for generator
criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr=0.001,
                        betas=(0.5, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=0.001,
                        betas=(0.5, 0.999))

for epoch in range(num_epochs):
    for i, data in enumerate(data_loader, 0):
        # 1st Step: Updating the weights of the neural network of the discriminator

        # We initialize to 0 the gradients of the discriminator with respect to  the weights.
        netD.zero_grad()

        # Training the discriminator with a real image of the dataset
        real, _ = data
        input = Variable(real)
        target = Variable(torch.ones(input.size()[0]))

        # We forward propagate this real image into the neural network of the discriminator to get the prediction (a value between 0 and 1).
        output = netD(input)

        errD_real = criterion(output, target)

        # Training the discriminator with a fake image generated by the generator
        noise = Variable(
            torch.randn(input.size()[0], 100, 1, 1))
        fake = netG(noise)
        target = Variable(torch.zeros(input.size()[0]))
        output = netD(fake.detach())
        errD_fake = criterion(output, target)

        # Backpropagating the total error
        errD = errD_real + errD_fake

        # We backpropagate the loss error by computing the gradients of the total error with respect to the weights of the discriminator.
        errD.backward()

        # We apply the optimizer to update the weights according to how much they are responsible for the loss error of the discriminator.
        optimizerD.step()

        # 2nd Step: Updating the weights of the neural network of the generator
        netG.zero_grad()
        target = Variable(torch.ones(input.size()[0]))
        output = netD(fake)
        errG = criterion(output, target)
        errG.backward()
        optimizerG.step()

        if i % 100 == 0:
            # 3rd Step: Printing the losses and saving the real images and the generated images of the batch every 100 steps
            print(f'[{epoch} {num_epochs}] [{i} {len(data_loader)}] Loss_D: {errD.data:.4f} Loss_G: {errG.data:.4f}')
            vutils.save_image(real, '/results/real_samples.png', normalize=True)
            fake = netG(noise)
            vutils.save_image(fake.data, f'./results/fake_samples_epoch_{epoch:05d}.png', normalize=True)
